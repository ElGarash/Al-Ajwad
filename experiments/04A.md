# Experiment 4

## Objective

The objective of this task was to finetune whisper to get better performance using audio augmentation (in progress).

---


## Experiment setup

  * Accelerator used for the expirement: GPU P100

  * Training was done on all ayat of the holy Quran that have a duration of 30 seconds or less.

  * The sampling rate of the training is 16kHz (resampling was done on the dataset).

  * Training was done on:
    - Abdul_Basit_Murattal_192kbps
    - Hudhaify_64kbps
    - Husary_128kbps
    - Mohammad_al_Tablaway_128kbps
    - Muhammad_Jibreel_64kbps
    - Ghamadi_40kbps

  * Validation was done on:
    - Minshawy_Murattal_128kbps
    - Yasser_Ad-Dussary_128kbps

---


## Methodology

### Approach

* `audiomentations` [[1](https://github.com/iver56/audiomentations)] was used for audio augmentation tasks.

* Making audio augmentation on the fly while training was not efficient because each epoch is a seperate run, for this reason I made a new dataset that contains the augmented audio files.

* Those are the `TimeStretch` effect parameters used to generate the augmented dataset:

  | Reciter                      | min_rate | max_rate |
  |------------------------------|----------|----------|
  | Husary_128kbps               |   0.9    |    2     |
  | Hudhaify_64kbps              |   0.7    |   1.5    |
  | Mohammad_al_Tablaway_128kbps |   0.85   |   1.85   |
  | Muhammad_Jibreel_64kbps      |   0.65   |   1.3    |
  | Abdul_Basit_Murattal_192kbps |   0.8    |   1.5    |
  | Ghamadi_40kbps               |   0.7    |   1.65   |


### Mistakes

* whisper is being trained on mono waveforms with 16kHz as a sampling rate, if the audio files contain mutliple channels you have to somehow get a mono waveform of that audio before flattening, skipping this step would cause the loaded waveform to have the content of channels side by side.

  ![original_waveform](./media/original_waveform.png)

  ![load_waveform](./media/load_waveform.png)

---

## Datasets

* augmented-dataset: https://www.kaggle.com/code/omartariq612/augmented-dataset/output

---


## Source code

  * augmented-dataset notebook: https://www.kaggle.com/code/omartariq612/augmented-dataset

---


## References

[1] audiomentations github repo: https://github.com/iver56/audiomentations