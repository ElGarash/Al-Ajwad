# Experiment 4: Second iteration on the auto annotation algorithm

## Objective

Update the algorithms used for segmentation to cover the cases that were not covered in the previous experiment (Experiment 3).

---

## Experiment setup

- All the work was done locally without using any accelerators and using Python 3.11 as the kernel of the experiment notebook.

- All the testing and tuning were done on the generated dataset from the Whisper large-v3 model with the audio of [sheikh AbdulBasit](https://everyayah.com/data/Abdul_Basit_Murattal_192kbps/), like Experiment 3.

- In the middle of this experiment, I found out that I have to see the repeated parts in the reference text of the Holy Quran to cover those cases, so I've done that and the results are at the end of this report.


---

## Methodology

### Approach

The approach was to make anchors on the reference text using the starting and ending words of each segment of the ayah that the model generated. Then, we would use these anchors to segment the reference text into segments that align with the segments generated by the model for each ayah. This can hold for the uncovered cases too but implementing it would be more complicated as we work on the letter level. **So, we will work on the word level.**

---

### code [[1]]

The splitting function:

```python
def find_spliting_indices_wordwise(aya_segments, ref_aya):
    anchors = [0]
    last_index = 0
    ref_words = ref_aya.split()
    for seg in aya_segments:
        idx_cpy = last_index
        if seg == "":
            continue
        seg_words = seg.split()
        start_word = seg_words[0]
        end_word   = seg_words[-1]

        # when the segment has more than one instance of the last word
        end_word_count = seg_words.count(end_word)
        if end_word_count > 1:
            for i in range(end_word_count-1):
                end_index = ref_words.index(end_word, last_index) if end_word in ref_words[last_index:] else -1
                # end_index = ref_aya.find(end_word, last_index)
                if end_index != -1:
                    last_index = end_index + 1
                    idx_cpy = last_index

        start_index = ref_words.index(start_word, idx_cpy) if start_word in ref_words[idx_cpy:] else -1
        end_index   = ref_words.index(end_word,   idx_cpy) if end_word   in ref_words[idx_cpy:] else -1
        # if the last word is not found try find the word before it
        if end_index == -1 and len(seg_words) > 1:
            before_end_word = seg_words[-2]
            end_index = ref_words.index(before_end_word) if before_end_word in ref_words else -1
            # assuming the word is not repeated and the word before it is found
            if end_index != -1: 
                end_index = end_index + 1

        # if the first word is not found try find the word after it
        if start_index == -1 and len(seg_words) > 1:
            after_start_word = seg_words[1]
            start_index = ref_words.index(after_start_word) if after_start_word in ref_words else -1
            if start_index != -1:
                start_index = start_index - 1

        if end_index != -1:
            last_index = end_index + 1
            anchors.append(last_index)

        if start_index != -1 and (start_index) not in anchors and start_index != 0:
            last_index = start_index
            if last_index > anchors[-1]:
                anchors.append(start_index)

    ref_words = ref_aya.split()
    anchors_letterwise = []
    for i in anchors:
        anchors_letterwise.append(len(" ".join(ref_words[:i])))

    return anchors_letterwise
```

The main loop is nearly the same:

```python
for shikh_index in range(len(shiekh_dataframes)):
    shiekh_df = shiekh_dataframes[shikh_index]
    ref_text = [""] * len(shiekh_df)
    gen_seg_num = [0] * len(shiekh_df) # number of generated segments for debugging
    ref_seg_num = [0] * len(shiekh_df) # number of reference segments for debugging
    for aya_name in tqdm(aya_names):
        aya_segments = get_aya_seg(aya_name, shiekh_df, reference_dataframe)
        if aya_segments['segments'] == []:
            continue
        ref_aya = aya_segments['ref']
        aya_segments = seg_cleaning(aya_segments['segments'])
        # ckpts = findSplitingIndices(aya_segments, ref_aya)
        anchors = find_spliting_indices_wordwise(aya_segments, ref_aya)
        ref_segments = get_reference_segments(anchors, ref_aya)

        # loop over the minimum number between the aya_segments and the ref_segments
        # if the pigeonhole principle is satisfied, then the rest of the segments will be added to the last segment
        aya_pigeonhole_indices = shiekh_df[(shiekh_df['sura'] == int(aya_name[:3])) & (shiekh_df['aya'] == int(aya_name[-3:]))].index.tolist()
        # if the aya_pigeonhole_indices is empty this happens when the ayah is not found in the generated dataframe
        if len(aya_pigeonhole_indices) == 0:
            continue

        ref_seg_num[aya_pigeonhole_indices[0]] = len(ref_segments)
        gen_seg_num[aya_pigeonhole_indices[0]] = len(aya_segments)
        
        if len(aya_segments) < len(ref_segments):
            for i in range(len(aya_segments)):
                ref_text[aya_pigeonhole_indices[i]] = ref_segments[i]
            ref_text[aya_pigeonhole_indices[len(aya_segments)-1]] += ' ' + ' '.join(ref_segments[len(aya_segments):])
        elif len(aya_segments) > len(ref_segments):
            for i in range(len(ref_segments)):
                ref_text[aya_pigeonhole_indices[i]] = ref_segments[i]
        else:
            for i in range(len(ref_segments)):
                ref_text[aya_pigeonhole_indices[i]] = ref_segments[i]
    shiekh_dataframes[shikh_index]['reference_text'] = ref_text
    # add a column with the difference between the number of words in the reference text and the generated text
    shiekh_dataframes[shikh_index]['diff'] = shiekh_dataframes[shikh_index].apply(lambda row: (len(row['reference_text'].split()) - len(row['text'].split())), axis=1)
    shiekh_dataframes[shikh_index]['gen_seg_num'] = gen_seg_num
    shiekh_dataframes[shikh_index]['ref_seg_num'] = ref_seg_num
```

## Results

<span style="color: #888888;">_Table 04B1_</span>
| sorah | ayah | start(s) | end(s) | duration(s) | text | reference_text | diff | GSN | RSN |
| ---- | --- | ----- | ----- | -------- | ---------------------------------------------------- | ---------------------------------------------------- | ---- | ----------- | ----------- |
| 1 | 0 | 0.0 | 3.8 | 3.8 | أعوذ بالله من الشيطان الرجيم | | -5 | 0 | 0 |
| 1 | 0 | 3.8 | 4.52 | 0.72 | رجيم | | -1 | 0 | 0 |
| 1 | 1 | 0.0 | 3.82 | 3.82 | بسم الله الرحمن الرحيم | بسم الله الرحمن الرحيم | 0 | 1 | 1 |
| 1 | 2 | 0.0 | 4.6 | 4.6 | الحمد لله رب العالمين | الحمد لله رب العالمين | 0 | 1 | 1 |
| 1 | 3 | 0.0 | 3.3 | 3.3 | الرحمن الرحيم | الرحمن الرحيم | 0 | 1 | 1 |
| 1 | 4 | 0.0 | 3.78 | 3.78 | مالك يوم الدين | مالك يوم الدين | 0 | 1 | 1 |
| 1 | 5 | 0.0 | 4.94 | 4.94 | إياك نعبد وإياك نستعين | إياك نعبد وإياك نستعين | 0 | 1 | 1 |
| 1 | 6 | 0.0 | 4.06 | 4.06 | اهدنا الصراط المستقيم | اهدنا الصراط المستقيم | 0 | 1 | 1 |
| 1 | 7 | 0.0 | 13.14 | 13.14 | صراط الذين أنعمت عليهم غير المغضوب عليهم ولا الضالين | صراط الذين أنعمت عليهم غير المغضوب عليهم ولا الضالين | 0 | 1 | 1 |
| 2 | 0 | 0.0 | 3.5 | 3.5 | بسم الله الرحمن الرحيم | | -4 | 0 | 0 |
| 2 | 1 | 0.0 | 7.0 | 7.0 | ألف لامين | الم | -1 | 1 | 1 |
| 2 | 2 | 0.0 | 3.9 | 3.9 | ذلك الكتاب لا ريب فيه | ذلك الكتاب لا ريب فيه | 0 | 2 | 2 |
| 2 | 2 | 3.9 | 7.4 | 3.5 | هدى للمتقين | هدى للمتقين | 0 | 0 | 0 |

### Data format

- sorah: the sorah number
- ayah: the ayah number
- start (s): the start time of the segment in the audio
- end (s): the end time of the segment in the audio
- duration (s): the duration of the segment in the audio
- text: the generated text
- reference_text: the reference text
- diff: the difference between the number of words in the reference text and the generated text
- GSN: the number of generated segments for each ayah, written in the first row of the ayah
- RSN: the number of reference segments (segmented by the algorithm) for each ayah, written in the first row of the ayah

---

## Notes

Regarding the output, the following points should be considered:
 - The algorithm shows improvement over the previous version.

<span style="color: #8888;">_Table 04B2_</span>

| sorah | ayah | start(s)| end(s)| duration(s)| text | reference_text | diff | GSN | RSN |
| ---- | --- | ----- | ------ | -------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- | ---- | ----------- | ----------- |
| 2    | 61  | 0	 | 23.98  | 23.98	 | وإذ قلتم يا موسى لن نصبر على طعام واحد فادع لنا ربك يخرج لنا مما تنبت الأرض من بقلها وقفائها | وإذ قلتم يا موسى لن نصبر على طعام واحد فادع لنا ربك يخرج لنا مما تنبت الأرض من بقلها وقثائها |	0 | 8           | 8|
| 2    | 61  | 23.98 | 44.9	  | 20.92	 | فادع لنا ربك يخرج لنا مما تنبت الأرض من بقلها وقفائها وفومها وعدسها وبصلها	| وفومها وعدسها وبصلها |	-11|	        0 |	0  |
| 2    | 61  | 44.9  | 53.96  | 9.06	 | قال أتستبدلون الذي هو أدنى بالذي هو أدنى |	قال أتستبدلون الذي هو أدنى |	-3|	0|	0 |
| 2    | 61  | 53.98 | 64.32  | 10.34	 | إهبطوا مصرا فإن لكم ما سألتم	بالذي هو خير | اهبطوا مصرا فإن لكم ما سألتم |	3|	0|	0 |
| 2    | 61  | 64.32 | 77.88  | 13.56	 | وضربت عليهم الذلة والمسكنة وباءوا بغضب من الله |	وضربت عليهم الذلة والمسكنة وباءوا بغضب من الله |	0|	0|	0 |
| 2    | 61  | 77.88 | 83.96  | 6.08     | ذلك بأنهم كانوا مصرين |	ذلك بأنهم كانوا يكفرون |	0|	0|	0 |
| 2    | 61  | 83.98 | 94.42  | 10.44	 | يكفرون بآيات الله ويقتلون النبيين بغير الحق |	بآيات الله ويقتلون النبيين بغير الحق |	-1|	0|	0 |
| 2    | 61  | 94.42 | 101.64 | 7.22	 | ذلك بما عصوا وكانوا يعتدون |	ذلك بما عصوا وكانوا يعتدون |	0|	0|	0|


The sheikh said the part: "فادع لنا ربك يخرج لنا مما تنبت الأرض من بقلها وقثائها" twice. The algorithm didn't work well with this ayah. The reference text is not correct. The algorithm should be modified to handle this case. (This case still exists in the current version of the algorithm)


## SubExperiment: Repeated parts in the reference text
### Objective
I found out that I have to see the repeated parts' cases in the reference text of the Holy Quran to cover those cases.

### Code [[2]]
```python
repeated_substrings = {} # key:(sura, aya), value: list of repeated substrings
phras_repeated = [0]*len(reference_dataframe)
for i in trange(len(reference_dataframe)):
    sura = reference_dataframe['sorah'][i]
    aya = reference_dataframe['ayah'][i]
    aya_text = " " + reference_dataframe['text'][i] + " "
    aya_text_split = aya_text.split()
    repeated_substrings[(sura, aya)] = {}
    for window_size in range(1, (len(aya_text_split)//2)+1):
        for start_idx in range(len(aya_text_split)-window_size):
            sub = " ".join(aya_text_split[start_idx:start_idx+window_size])
            num = aya_text.count(' '+sub+' ', len(' '.join(aya_text_split[:start_idx])))
            if num > 1:
                repeated_substrings[(sura, aya)][sub] = num
                if window_size > 1:
                    phras_repeated[i] += 1
```

### Results

```py
for i in range(0, 10):
    n = len(diff_df[diff_df['phrase_repeated'] > i])
    print(f"{n}\tayas that have {i+1}\tor more of repeated phrases")
```

<span style="color: #8888;">_Table 04B3_</span>
|number of repeated segments|number of ayahs|
|--------------------------|--------------|
|>1                        |277           |
|>2                        |91            |
|>3                        |72            |
|>4                        |43            |
|>5                        |29            |
|>6                        |26            |
|>7                        |12            |
|>8                        |10            |
|>9                        |10            |
|>10                       |8             |


#### Notes
We will make a UI app that will help our volunteers correct the mistakes in the output of the algorithm.

## Conclusion
- The algorithm needs a human to check the output and correct it.

[1]: https://www.kaggle.com/abdo3id/aya-segments-splitter
[2]: https://www.kaggle.com/code/abdo3id/repeated-parts-holy-quran